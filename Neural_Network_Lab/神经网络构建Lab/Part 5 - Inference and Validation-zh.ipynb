{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推理与验证\n",
    "\n",
    "在训练神经网络之后，你现在可以使用它来进行预测。这种步骤通常被称作**推理**，这是一个借自统计学的术语。然而，神经网络在面对训练数据时往往表现得*太过优异*，因而无法泛化未见过的数据。这种现象被称作**过拟合**，它损害了推理性能。为了在训练时检测过拟合，我们测量并不在名为**验证集**的训练集中数据的性能。在训练时，我们一边监控验证性能，一边进行正则化，如 Dropout，以此来避免过拟合。在这个 notebook 中，我将向你展示如何在 PyTorch 中做到这一点。\n",
    "\n",
    "首先，我会实现我自己的前馈神经网络，这个网络基于第四部分的练习中的 Fashion-MNIST 数据集构建。它是第四部分练习的解决方案，也是如何进行 Dropout 和验证的例子。\n",
    "\n",
    "向往常一样，我们先通过 torchvision 来加载数据集。你将会在下一部分更深入地学习有关 torchvision 和加载数据的知识。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "\n",
    "跟 MNIST 数据集一样，Fashion-MNIST 数据集中每张图片的像素为 28x28，共 784 个数据点和 10 个类。我使用了 `nn.ModuleList` 来加入任意数量的隐藏层。这个模型中的 `hidden_layers` 参数为隐藏层大小的列表（以整数表示）。使用 `nn.ModuleList` 来寄存每一个隐藏模块，这样你可以在之后使用模块方法。\n",
    "\n",
    "我还使用了 `forward` 方法来返回输出的 log-softmax。由于 softmax 是类的概率分布，因此 log-softmax 是一种对数概率，它有[许多优点](https://en.wikipedia.org/wiki/Log_probability)。使用这种对数概率，计算往往会更加迅速和准确。为了在之后获得类的概率，我将需要获得输出的指数（`torch.exp`）。\n",
    "\n",
    "我们可以使用 [`nn.Dropout`](http://pytorch.org/docs/master/nn.html#dropout) 来在我们的网络中加入 Dropout。这与 `nn.Linear` 等其他模块的作用相似。它还将 Dropout 概率作为一种输入传递到网络中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n",
    "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            input_size: integer, size of the input\n",
    "            output_size: integer, size of the output layer\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers\n",
    "            drop_p: float between 0 and 1, dropout probability 丢弃的概率\n",
    "        '''\n",
    "        super().__init__()\n",
    "        # Add the first layer, input to a hidden layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        # 这里不再手动设置 而是写成参数形式 传入\n",
    "        # Add a variable number of more hidden layers  设置随机数量的隐藏层\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        # 扩展列表\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        # 丢弃模块 因为使用丢弃法dropout 这里drop_p作为网络的参数传入\n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        \n",
    "        for each in self.hidden_layers:\n",
    "            x = F.relu(each(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        # 使用log的softmax 获得更好的数字\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练网络\n",
    "\n",
    "由于该模型的前向方法返回 log-softmax，因此我使用了[负对数损失](http://pytorch.org/docs/master/nn.html#nllloss) 作为标准。我还选用了[Adam 优化器](http://pytorch.org/docs/master/optim.html#torch.optim.Adam)。这是一种随机梯度下降的变体，包含了动量，并且训练速度往往比基本的 SGD 要快。\n",
    "\n",
    "我还加入了一个代码块来测量验证损失和精确度。由于我在这个神经网络中使用了 Dropout，在推理时我需要将其关闭，否则这个网络将会由于许多连接的关闭而表现糟糕。在 PyTorch 中，你可以使用 `model.train()` 和 `model.eval()` 来将模型调整为“训练模式”或是“评估模式”。在训练模式中，Dropout 为开启状态，而在评估模式中，Dropout 为关闭状态。这还会影响到其他模块，包括那些应该在训练时开启、在推理时关闭的模块。\n",
    "\n",
    "这段验证代码由一个通过验证集（并分裂成几个批次）的前向传播组成。我根据 log-softmax 输出来计算验证集的损失以及预测精确度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=500, bias=True)\n",
       "  )\n",
       "  (output): Linear(in_features=500, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the network, define the criterion and optimizer\n",
    "# 传入参数 784输入 10个输出 500个单元作为隐藏层 也可以传入一个列表[500, 200，xxx] 作为多层的单元\n",
    "# 比如上面的[500,200,100]即有三个隐藏层 每层分别有500个单元200个单元100个单元...\n",
    "# 丢弃的概率为0.5\n",
    "model = Network(784, 10, [500], drop_p=0.5)\n",
    "# 定义损失函数 负对数似然损失 对分类有效 \n",
    "criterion = nn.NLLLoss()\n",
    "# 使用Adam优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# 输出model观察一下\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:35: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2..  Training Loss: 1.040..  Test Loss: 0.711..  Test Accuracy: 0.739\n",
      "Epoch: 1/2..  Training Loss: 0.697..  Test Loss: 0.627..  Test Accuracy: 0.763\n",
      "Epoch: 1/2..  Training Loss: 0.668..  Test Loss: 0.620..  Test Accuracy: 0.758\n",
      "Epoch: 1/2..  Training Loss: 0.617..  Test Loss: 0.552..  Test Accuracy: 0.798\n",
      "Epoch: 1/2..  Training Loss: 0.608..  Test Loss: 0.558..  Test Accuracy: 0.800\n",
      "Epoch: 1/2..  Training Loss: 0.573..  Test Loss: 0.518..  Test Accuracy: 0.807\n",
      "Epoch: 1/2..  Training Loss: 0.558..  Test Loss: 0.515..  Test Accuracy: 0.808\n",
      "Epoch: 1/2..  Training Loss: 0.527..  Test Loss: 0.503..  Test Accuracy: 0.809\n",
      "Epoch: 1/2..  Training Loss: 0.528..  Test Loss: 0.541..  Test Accuracy: 0.796\n",
      "Epoch: 1/2..  Training Loss: 0.533..  Test Loss: 0.490..  Test Accuracy: 0.819\n",
      "Epoch: 1/2..  Training Loss: 0.497..  Test Loss: 0.483..  Test Accuracy: 0.822\n",
      "Epoch: 1/2..  Training Loss: 0.503..  Test Loss: 0.469..  Test Accuracy: 0.828\n",
      "Epoch: 1/2..  Training Loss: 0.532..  Test Loss: 0.474..  Test Accuracy: 0.823\n",
      "Epoch: 1/2..  Training Loss: 0.501..  Test Loss: 0.469..  Test Accuracy: 0.826\n",
      "Epoch: 1/2..  Training Loss: 0.499..  Test Loss: 0.494..  Test Accuracy: 0.818\n",
      "Epoch: 1/2..  Training Loss: 0.488..  Test Loss: 0.455..  Test Accuracy: 0.828\n",
      "Epoch: 1/2..  Training Loss: 0.506..  Test Loss: 0.482..  Test Accuracy: 0.825\n",
      "Epoch: 1/2..  Training Loss: 0.474..  Test Loss: 0.449..  Test Accuracy: 0.834\n",
      "Epoch: 1/2..  Training Loss: 0.465..  Test Loss: 0.471..  Test Accuracy: 0.825\n",
      "Epoch: 1/2..  Training Loss: 0.482..  Test Loss: 0.459..  Test Accuracy: 0.833\n",
      "Epoch: 1/2..  Training Loss: 0.500..  Test Loss: 0.462..  Test Accuracy: 0.833\n",
      "Epoch: 1/2..  Training Loss: 0.491..  Test Loss: 0.457..  Test Accuracy: 0.830\n",
      "Epoch: 1/2..  Training Loss: 0.516..  Test Loss: 0.444..  Test Accuracy: 0.837\n",
      "Epoch: 2/2..  Training Loss: 0.448..  Test Loss: 0.446..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.445..  Test Loss: 0.440..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 0.477..  Test Loss: 0.450..  Test Accuracy: 0.830\n",
      "Epoch: 2/2..  Training Loss: 0.470..  Test Loss: 0.447..  Test Accuracy: 0.834\n",
      "Epoch: 2/2..  Training Loss: 0.475..  Test Loss: 0.450..  Test Accuracy: 0.833\n",
      "Epoch: 2/2..  Training Loss: 0.427..  Test Loss: 0.438..  Test Accuracy: 0.838\n",
      "Epoch: 2/2..  Training Loss: 0.479..  Test Loss: 0.419..  Test Accuracy: 0.847\n",
      "Epoch: 2/2..  Training Loss: 0.446..  Test Loss: 0.426..  Test Accuracy: 0.847\n",
      "Epoch: 2/2..  Training Loss: 0.437..  Test Loss: 0.433..  Test Accuracy: 0.841\n",
      "Epoch: 2/2..  Training Loss: 0.454..  Test Loss: 0.428..  Test Accuracy: 0.844\n",
      "Epoch: 2/2..  Training Loss: 0.454..  Test Loss: 0.438..  Test Accuracy: 0.842\n",
      "Epoch: 2/2..  Training Loss: 0.463..  Test Loss: 0.444..  Test Accuracy: 0.839\n",
      "Epoch: 2/2..  Training Loss: 0.466..  Test Loss: 0.412..  Test Accuracy: 0.848\n",
      "Epoch: 2/2..  Training Loss: 0.453..  Test Loss: 0.421..  Test Accuracy: 0.847\n",
      "Epoch: 2/2..  Training Loss: 0.456..  Test Loss: 0.419..  Test Accuracy: 0.846\n",
      "Epoch: 2/2..  Training Loss: 0.429..  Test Loss: 0.423..  Test Accuracy: 0.848\n",
      "Epoch: 2/2..  Training Loss: 0.427..  Test Loss: 0.424..  Test Accuracy: 0.846\n",
      "Epoch: 2/2..  Training Loss: 0.425..  Test Loss: 0.421..  Test Accuracy: 0.848\n",
      "Epoch: 2/2..  Training Loss: 0.443..  Test Loss: 0.431..  Test Accuracy: 0.843\n",
      "Epoch: 2/2..  Training Loss: 0.474..  Test Loss: 0.420..  Test Accuracy: 0.844\n",
      "Epoch: 2/2..  Training Loss: 0.447..  Test Loss: 0.403..  Test Accuracy: 0.853\n",
      "Epoch: 2/2..  Training Loss: 0.420..  Test Loss: 0.422..  Test Accuracy: 0.845\n",
      "Epoch: 2/2..  Training Loss: 0.433..  Test Loss: 0.415..  Test Accuracy: 0.848\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 40\n",
    "for e in range(epochs):\n",
    "    # 模型在训练时 启用dropout\n",
    "    model.train()\n",
    "    for images, labels in iter(trainloader):\n",
    "        steps += 1\n",
    "        # Flatten images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        # Wrap images and labels in Variables so we can calculate gradients\n",
    "        inputs = Variable(images)\n",
    "        targets = Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(inputs)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            # 模型在推理阶段 不能启用dropout\n",
    "            model.eval() # 在评估阶段\n",
    "            \n",
    "            accuracy = 0\n",
    "            test_loss = 0\n",
    "            for ii, (images, labels) in enumerate(testloader):\n",
    "                \n",
    "                images = images.resize_(images.size()[0], 784)\n",
    "                # 将volatile设为True 意味着不想进行反向传播遍历 因为在推理时 我们不需要用推理的\n",
    "                # 数据将其也作为训练集 来反向传播并更新权重\n",
    "                inputs = Variable(images, volatile=True)\n",
    "                labels = Variable(labels, volatile=True)\n",
    "\n",
    "                output = model.forward(inputs)\n",
    "                test_loss += criterion(output, labels).data[0]\n",
    "                \n",
    "                ## Calculating the accuracy \n",
    "                # 模型输出的是log_softmax, 如果对其求对数即可获得各类之间的softmax概率分布\n",
    "                ps = torch.exp(output).data\n",
    "                # 测试标实际标签是否和预测的一样 这里的ps是概率分布 判断模型预测了对不对\n",
    "                # 然后对其取最大值 即返回最大的概率 即最有可能的那个标签 的索引（取[1]\n",
    "                equality = (labels.data == ps.max(1)[1])\n",
    "                # 即网络所作的正确推理除以预测的总次数 可以是一堆0和1 我们取均值即可 \n",
    "                # 真是1 假是0 正确了即1 错误了为0 那么整个准确率即为这个equality的均值\n",
    "                accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "            \n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "            \n",
    "            running_loss = 0\n",
    "            \n",
    "            # 要确保验证完之后将模型重置为训练模式\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推理\n",
    "\n",
    "模型已经训练好了，我们现在可以使用它来进行推理。之前已经进行过这一步骤，但现在我们需要使用 `model.eval()` 来将模型设置为推理模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f546cc3b438>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 224,
       "width": 423
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test out your network!\n",
    "# 注意要设置成推理模式！！！\n",
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.resize_(1, 784)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "output = model.forward(Variable(img, volatile=True))\n",
    "ps = torch.exp(output)\n",
    "\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img.resize_(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下一步！\n",
    "\n",
    "在下一部分，我将为你展示如何保存训练好的模型。一般来说，你不会希望在每次使用模型时都要重新训练，而是希望在训练好模型之后将其保存，以便下次训练或推理时使用。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
